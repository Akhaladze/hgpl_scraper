version: '3.8'
services:
  
  # Scraper Applications ############################################################################
  # 1. `Scraper INIT` - Scraper Application
  # 2. `Scraper_worker` - Scraper Worker Application
  # 3. `Scraper_scheduler` - Scraper Scheduler Application
  # 4. `Scraper_celery_flower` - Scraper Celery Flower Application
  # 5. `Scraper_celery_beat` - Scraper Celery Beat Application
  # 6. `Scraper_celery_worker` - Scraper Celery Worker Application
  ####################################################################################################
  
  ###################################################################################################
  # 6:: Scraper_celery_worker
  ###################################################################################################
  
  worker:
    build:
      context: ./
      dockerfile: Dockerfile
    entrypoint: celery
    command: -A tasks worker -l info -E
    user: nobody
    volumes:
      - ./project/:/data
    networks:
      scraper_network:
          ipv4_address: 192.168.65.60
    environment:
      - CELERY_BROKER_URL=amqp://scraper:scraper@rabbitmq:5672/scraper_app
      - CELERY_RESULT_BACKEND=redis://redis:6379/0
      - PYTHONPATH=/data
      - COMPOSE_PROJECT_NAME=scraper
    depends_on:
      - rabbitmq
      - redis
      - scraper_db

  # Scraper Infrastructure Services ################################################################
  # 1. RabbitMQ
  # 2. Postgres DB (HC)
  # 3. Persistent Storage (!NOT ADDED YET!)
  # 4. PgAdmin
  # 5. Redis
  # 6. Networks
  ###################################################################################################
  ###################################################################################################
  # DB:: Scraper_DB
  ###################################################################################################
  rabbitmq:
    image: rabbitmq:3.12.4-management
    #user: "gnet:gnet"
    ports:
      - 15672:15672
      - 5672:5672
      - 1883:1883
    container_name: rabbitmq
    environment:
      - RABBITMQ_DEFAULT_USER=scraper
      - RABBITMQ_DEFAULT_PASS=scraper
      - RABBITMQ_DEFAULT_VHOST=scraper_app
      - RABBITMQ_SERVER_ADDITIONAL_ERL_ARGS=-rabbit log_levels [{connection,error},{default,error}] disk_free_limit 2147483648 -rabbitmq_management listener [{port,15672},{ip,"192.168.65.80"}]
      - COMPOSE_PROJECT_NAME=scraper
    volumes:
      - rabbitmq_data:/var/lib/rabbitmq:wr
      - ./configs/mq/enabled_plugins:/etc/rabbitmq/enabled_plugins
      - ./configs/mq/rabbitmq.conf:/etc/rabbitmq/rabbitmq.conf
    restart: unless-stopped
    networks:
      scraper_network:
          ipv4_address: 192.168.65.80
    hostname: rabbitmq
  ###################################################################################################
  # DB:: Scraper_DB
  ###################################################################################################
  scraper_db:
    image: postgres:15.4
    volumes: 
    # - ./configs/init.sql:/docker-entrypoint-initdb.d/init.sql
    # - ./configs/db/script.sql:/docker-entrypoint-initdb.d/create_tables.sql
      - scraper_db:/var/lib/postgresql/data
    ports:
      - 5432:5432
    container_name: scraper_db
    hostname: scraper_db
    env_file:
      - ./configs/.env_db
    #shm_size: 8gb
    restart: unless-stopped
    networks:
      scraper_network:
        ipv4_address: 192.168.65.90
    environment:
      - COMPOSE_PROJECT_NAME=scraper
    #depends_on:
    #  Scraper_db:
    #    condition: service_healthy

  ###################################################################################################
  # PG ADMIN
  ###################################################################################################
  pgadmin:
    image: dpage/pgadmin4:latest
    #user: "gnet:gnet"
    env_file: ./configs/.env_pgadmin
    restart: unless-stopped
    volumes:
      - pgadmin:/var/lib/pgadmin
    networks:
      scraper_network:
        ipv4_address: 192.168.65.110
    ports:
      - 80:80
    hostname: scraper_pgadmin
    environment:
      - COMPOSE_PROJECT_NAME=scraper

  ###################################################################################################
  # REDIS
  ###################################################################################################
  redis:
    image: redis:latest
    #user: "gnet:gnet"
    hostname: redis
    container_name: redis
    ports:
      - 6379:6379
    env_file: ./configs/.env_redis
    networks:
      scraper_network:
        ipv4_address: 192.168.65.130
    restart: unless-stopped
    environment:
      - COMPOSE_PROJECT_NAME=scraper
    volumes:
      - redis:/data
  ###################################################################################################
  # Celery Flower (Tasks monitoring service)
  ###################################################################################################
  flower:
    build: ./
    command: celery -A tasks flower
    volumes:
      - ./project:/data
    working_dir: /data
    networks:
      scraper_network:
        ipv4_address: 192.168.65.140
    ports:
      - 5555:5555
    environment:
      - CELERY_BROKER_URL=amqp://scraper:scraper@rabbitmq/scraper_app
      - CELERY_RESULT_BACKEND=redis://redis/0
      - FLOWER_UNAUTHENTICATED_API=true
      - COMPOSE_PROJECT_NAME=scraper
    depends_on:
      #- worker
      - redis
      - rabbitmq
      - scraper_db
  
  ###################################################################################################
  # Network #########################################################################################
  # Volumes #########################################################################################
  # Labels  #########################################################################################
  # #################################################################################################
networks: 
  scraper_network:
    driver: bridge
    ipam: 
      config:
        - subnet: 192.168.65.0/24
          ip_range: 192.168.65.0/24
          gateway: 192.168.65.1
    #external: true
    attachable: true
    internal: false
    name: scraper_network
    labels:
      - com.docker.compose.labels=mlparser,scraper
volumes:
  rabbitmq_data:
  scraper_db:
  pgadmin:
  redis:
    driver: local
  # downloads folder (SDS Storage)
  full_data:
     external: true


